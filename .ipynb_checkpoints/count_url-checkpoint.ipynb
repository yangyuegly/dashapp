{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # New Orleans Dataset\n",
    "# \n",
    "# Mileva Van Tuyl\n",
    "# Funing Yang\n",
    "# Daphka Alius\n",
    "# Jane Yang\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from collections import OrderedDict\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "fake_news_accounts = [\n",
    "'NewOrleansON',\n",
    "'ElPasoTopNews',\n",
    "'DailySanJose',\n",
    "'ChicagoDailyNew',\n",
    "'DailySanFran',\n",
    "'DetroitDailyNew',\n",
    "'TodayCincinnati',\n",
    "'MinneapolisON',\n",
    "'KansasDailyNews',\n",
    "'TodayBostonMA',\n",
    "'TodayPittsburgh',\n",
    "'Seattle_Post',\n",
    "'PhiladelphiaON',\n",
    "'DailyLosAngeles',\n",
    "'HoustonTopNews',\n",
    "'DailySanDiego',\n",
    "'DallasTopNews',\n",
    "'WashingtOnline',\n",
    "'TodayNYCity',\n",
    "'OnlineCleveland',\n",
    "'SanAntoTopNews',\n",
    "'PhoenixDailyNew',\n",
    "'TodayMiami',\n",
    "'Atlanta_Online',\n",
    "'Baltimore0nline',\n",
    "'OaklandOnline',\n",
    "'StLouisOnline']\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def URL(allTweets):\n",
    "    NOTweets = allTweets # get all New Orleans tweets\n",
    "    NODTList = [tweet[2] for tweet in NOTweets] # take only the timestamp\n",
    "\n",
    "    # create a dictionary that maps each timestamp to the count 1 (since it corresponds to one tweet)\n",
    "    data = OrderedDict([('tweet_time', NODTList), ('count', [1]*len(NODTList))])\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.head()\n",
    "\n",
    "    # make the first column of type DateTimeIndex\n",
    "    df['tweet_time'] = pd.to_datetime(df['tweet_time'])\n",
    "    df = df.set_index('tweet_time')\n",
    "    df.head()\n",
    "\n",
    "    df['count'].resample('M').sum()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "##getting start and end dates\n",
    "#startDates = []\n",
    "#endDates = []\n",
    "#\n",
    "#with open('start-end-dates-fake-accounts.json','r') as inputFile:\n",
    "#        dates = json.load(inputFile)\n",
    "#    \n",
    "#for acc in fake_news_accounts:\n",
    "#    startDates.append((pd.to_datetime(dates[acc][0])).date())\n",
    "#    endDates.append((pd.to_datetime(dates[acc][1])).date())\n",
    "#\n",
    "#all_datelist={}\n",
    "#for i in range(len(fake_news_accounts)):\n",
    "#    all_datelist[fake_news_accounts[i]]=(pd.date_range(startDates[i],endDates[i], freq='M').tolist())\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#generate x-axis dates using start and end date of NewOrleansON\n",
    "startDate = pd.to_datetime(\"2014-09-11\"); #start date for NO\n",
    "endDate = pd.to_datetime(\"2017-08-08\"); #end date for NO\n",
    "datelist = (pd.date_range(startDate,endDate, freq='M').tolist())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def getTweetsFromNews(newsName):\n",
    "    with open(newsName+'.txt','r') as inputFile:\n",
    "        curr = json.load(inputFile)\n",
    "        curr.sort(key = lambda aList: aList[13])\n",
    "    return curr\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "def URLRatio (newsName, tweets):\n",
    "    counterFURLs=[]\n",
    "    numFakeTweets = []    \n",
    "\n",
    "    monthly_fakeTweets = []\n",
    "    \n",
    "    for i in range(len(datelist)-1):\n",
    "        curr_month = []\n",
    "        for ftweet in tweets: \n",
    "            curr = pd.to_datetime(ftweet[13])\n",
    "            curr = curr.date()\n",
    "            if curr>=datelist[i].date() and curr<=datelist[i+1].date():\n",
    "                curr_month.append(ftweet)\n",
    "             #   fakeNewsList.remove(ftweet)\n",
    "            elif curr>datelist[i+1].date():\n",
    "                #print(curr_month)\n",
    "                monthly_fakeTweets.append(curr_month)\n",
    "                break     \n",
    "    monthly_fakeTweets.append(curr_month)  #in the case where the current month is the last\n",
    "    #print(monthly_fakeTweets[3])\n",
    "    \n",
    "    \n",
    "    numFakeTweets=[len(each_month) for each_month in monthly_fakeTweets]\n",
    "    for current_month in monthly_fakeTweets:\n",
    "        curr_counter = 0\n",
    "        for ftweet in current_month:\n",
    "            if '://' in ftweet[28]:\n",
    "                #print(ftweet[28])\n",
    "                curr_counter+=1                \n",
    "        counterFURLs.append(curr_counter)\n",
    "   #     print(counterFURLs)\n",
    "   #    print(ftweet[28])\n",
    "    counterNoFURLs = []\n",
    "    counterNoFURLs= [i - j for i, j in zip(numFakeTweets, counterFURLs)] \n",
    "    print(newsName)\n",
    "    print(counterNoFURLs)\n",
    "    print(counterFURLs)\n",
    "\n",
    "\n",
    " #   ratioWithURLs=(counterFURLs/numFakeTweets)\n",
    "#  ratioNoURLs=(counterNoFURLs/numFakeTweets)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for news in fake_news_accounts:\n",
    "    no = getTweetsFromNews(news)\n",
    "    URLRatio(news,no)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
